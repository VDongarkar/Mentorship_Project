{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fa529a5f-dfb1-45d9-95b4-98d0d46e14ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "# import os\n",
    "# from langchain_openai import ChatOpenAI\n",
    "\n",
    "# model = ChatOpenAI(model=\"gpt-3.5-turbo\", api_key=\"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\")\n",
    "import os\n",
    "import google.generativeai as genai\n",
    "\n",
    "os.environ[\"GOOGLE_API_KEY\"] = \"AIzaSyB5RDXy9qJxHbg2EaTJ77aDBoniBESYeLE\"\n",
    "genai.configure(api_key=os.environ[\"GOOGLE_API_KEY\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "53b74318-1001-40f4-8138-505bd2bbc3a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools.tavily_search import TavilySearchResults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1fa3c507-9960-415b-b9c7-007d180f2607",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_community.tools.tavily_search.tool.TavilySearchResults'>\n",
      "tavily_search_results_json\n"
     ]
    }
   ],
   "source": [
    "tool = TavilySearchResults(max_results=4, tavily_api_key=\"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\")\n",
    "print(type(tool))\n",
    "print(tool.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "526bf2ae-1396-47c0-9561-e6192394e6e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "###!pip install langgraph langchain openai langchain-openai langchain-community tavily-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9e534545-a638-403e-b0c6-fd067ad33c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "####!pip install --upgrade langchain-community tavily-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f710a7f9-3e8f-4dd2-b930-a185375695d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph,END\n",
    "from typing import TypedDict,Annotated,Any,Dict\n",
    "import operator \n",
    "from langchain_core.messages import AnyMessage, SystemMessage ,HumanMessage \n",
    "# from langchain_openai import ChatOpenAI\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4ea06a4a-b882-4d6f-aac7-81053e6847d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgentState(TypedDict):\n",
    "    messages: Annotated[list[AnyMessage], operator.add]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "043e2bba-6296-486d-b41e-96332b64f8da",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent:\n",
    "    def __init__(self, model, tools, system=\"\"):\n",
    "        self.system = system\n",
    "        \n",
    "        graph = StateGraph(AgentState)\n",
    "        graph.add_node(\"llm\", self.call_gemini)   \n",
    "        graph.add_node(\"action\", self.take_action)\n",
    "        \n",
    "        graph.add_conditional_edges(\n",
    "            \"llm\",\n",
    "            self.exists_action,\n",
    "            {True: \"action\", False: END}\n",
    "        )\n",
    "\n",
    "        graph.add_edge(\"action\", \"llm\")  \n",
    "        graph.set_entry_point(\"llm\")  \n",
    "        self.graph = graph.compile()\n",
    "\n",
    "        self.tools = {t.name: t for t in tools}\n",
    "        self.model = model.bind_tools(tools)\n",
    "\n",
    "    def exists_action(self, state: AgentState):\n",
    "        result = state[\"messages\"][-1]\n",
    "        return len(result.tool_calls) > 0  \n",
    "\n",
    "    def call_gemini(self, state: AgentState):\n",
    "       \n",
    "        messages = state[\"messages\"]\n",
    "        if self.system:\n",
    "            messages = [SystemMessage(content=self.system)] + messages\n",
    "\n",
    "        message = self.model.invoke(messages)  \n",
    "        return {\"messages\": [message]}\n",
    "\n",
    "    def take_action(self, state: AgentState):\n",
    "        \n",
    "        tool_calls = state[\"messages\"][-1].tool_calls\n",
    "        results = []\n",
    "\n",
    "        for t in tool_calls:\n",
    "            print(f\"Calling tool: {t}\")\n",
    "            if t[\"name\"] not in self.tools: \n",
    "                print(\"\\n ....bad tool name....\")\n",
    "                result = \"Invalid tool name, retry\"\n",
    "            else:\n",
    "                result = self.tools[t[\"name\"]].invoke(t[\"args\"])  \n",
    "            results.append(ToolMessage(tool_call_id=t[\"id\"], name=t[\"name\"], content=str(result)))\n",
    "\n",
    "        print(\"Back to model!\")\n",
    "        return {\"messages\": results}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7e90e201-c37a-44a9-b38f-de792f749d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"You are a smart research assistant. Use the search engine to look up information. \\\n",
    "You are allowed to make multiple calls (either together or in sequence). \\\n",
    "Only look up information when you are sure of what you want. \\\n",
    "If you need to look up some information before asking a follow up question, you are allowed to do that!\n",
    "\"\"\"\n",
    "model = ChatGoogleGenerativeAI(model=\"gemini-1.5-pro\")\n",
    "##model = ChatOpenAI(model=\"gpt-3.5-turbo\")  #reduce inference cost\n",
    "abot = Agent(model,[], system=prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c86b7786-124f-4fbf-b93f-b994362f18a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain_core.messages import ToolMessage\n",
    "# messages = [HumanMessage(content=\"What is 19 * 75?\")]\n",
    "# result = abot.graph.invoke({\"messages\": messages})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bf3ad80d-ae4c-465f-a752-c68fa1cc13dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import ToolMessage\n",
    "messages = [HumanMessage(content=\"What is the capital of India?\")]\n",
    "result = abot.graph.invoke({\"messages\": messages})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "68552f91-614c-4291-b538-af233a5e9bad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='What is the capital of India?', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='The capital of India is New Delhi.', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-1.5-pro-002', 'safety_ratings': []}, id='run-9e336ac5-dea0-4989-855e-3671e56e8beb-0', usage_metadata={'input_tokens': 73, 'output_tokens': 9, 'total_tokens': 82, 'input_token_details': {'cache_read': 0}})]}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3c9b2871-34c0-473b-9ac3-90402e8dbea5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The capital of India is New Delhi.'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result['messages'][-1].content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c5c31dd1-c786-4751-a237-f7c38885f922",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "India is a vast country with diverse climates. To give you a useful weather report, I need to know which city or region you're interested in.  Could you please specify the location?\n"
     ]
    }
   ],
   "source": [
    "print(result['messages'][-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2704f666-3003-4897-9074-b82579531030",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import ToolMessage\n",
    "messages = [HumanMessage(content=\"What is the capital of Maharashtra?\")]\n",
    "result = abot.graph.invoke({\"messages\": messages})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "749d31e1-5da2-4cd8-be25-7fb14fb37ae8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='What is the capital of Maharashtra?', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='The capital of Maharashtra is Mumbai.', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-1.5-pro-002', 'safety_ratings': []}, id='run-11b3a353-c614-4862-9669-a07cb2578c3c-0', usage_metadata={'input_tokens': 73, 'output_tokens': 8, 'total_tokens': 81, 'input_token_details': {'cache_read': 0}})]}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6302f4e4-68d1-4703-aff0-1a44ac18b96e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The capital of Maharashtra is Mumbai.'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result['messages'][-1].content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "632f61ce-5e5d-469b-912f-080ee2898300",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
